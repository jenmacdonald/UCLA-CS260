{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load, parse, and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SciPy, Pandas, Seaborn\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import datasets, classifiers, performance metrics, and shuffle\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACUxJREFUeJzt3X+oX3Udx/HXqy2TUHc3yj805W75hxF1L9sQpMiNHBlW\n26gtSKERuUH/NArZ/jCZFXQHVrOguPZrhBXuBjoUpLZgKyXNre4gi4Rtl7Wmo5z3bpqYy3d/nO/w\nJnrP5+6e74/3d88HDO939/0953Pffu/rnnu+573jiBAAII+3dHsBAIDZIbgBIBmCGwCSIbgBIBmC\nGwCSIbgBIJl0wW17nu0XbF/dZC0q9Ld96G37XGi9bXtwtxp07s+rtl+a9viW2W4vIv4bEZdExLEm\na5tg+3bbz9qesv1D2xd1YJ8XRH9tD9n+te3nbJ9t9/5a+7xQevs523+0fdr2cdvfsD2vzfu8UHp7\ni+2/tXp70vZPbF8y5+12cgDH9oSkz0fE3hlq5kdER74xm2T7Zkk/krRS0klJuyXtj4g7OriGCfVv\nf98j6XpJk5J2RcT8Du9/Qv3b2y9IOiTpSUmXS3pY0n0RcXeH9j+h/u3t1ZJejoiTti+V9ANJJyLi\nS3PZbtdPldj+uu37bf/C9hlJt9q+3vbjtidtP2P7O7bf2qqfbztsD7Ye39f6/CO2z9j+ve3Fs61t\nff6jtp9uHTF/1/ZjtjcUfimflXRvRPw1Ik5J+pqk0ue2Tb/0t9XXH0v6S4PtmZM+6u33IuKxiPhP\nRByX9HNJH2iuU7PXR709FhEnp/3Vq5KumWt/uh7cLWtVvVgWSLpf0llJX5T0DlUvoJskbZrh+Z+R\n9BVJiyQdUxWas6q1fbmkXZJub+33qKTrzj3J9uLWC+aKN9nue1UdtZxzSNKVthfMsJZO6Yf+9qp+\n7O2HJD1VWNtOfdFb2zfYnpJ0WtInJO2YYR1FeiW4H42IhyLi1Yh4KSKejIgnIuJsRByRdK+kG2Z4\n/i8j4kBEvCLpZ5KGz6P2Y5LGI2J363PflvSvc0+KiKMRMRARJ95ku5dImpr2+HTrv5fOsJZO6Yf+\n9qq+6q3t2yS9X9K36mo7oC96GxH7I2KBpKsk3a3qB8OcdPQ84Qz+Pv2B7WslfVPSMklvV7XOJ2Z4\n/rPTPv63qhCdbe0V09cREWH7eO3KX/OCpMumPT53pH1mFttol37ob6/qm97a/qSqI80Pt073dVvf\n9Lb13OO296r6LeK6uvqZ9MoR9+vfIR2V9GdJ10TEZZLulOQ2r+EZSe8698C2JV05i+c/JWlo2uMh\nSf+IiKk3qe+kfuhvr+qL3rp6c/37km6OiF44TSL1SW9fZ76kd891Ub0S3K93qarTDi+6uppgpvNY\nTXlY0lLbH7c9X9W5tHfO4vk/lXSb7WttL5J0h6SdzS+zEen668rFki5qPb7YHbjc8jxk7O0qVa/f\ntRFxsE1rbELG3t5q+6rWx4OqfqP5zVwX1avB/WVVV2mcUfVT9v5277D1zu+nVZ3be07VT8U/SXpZ\nkmwvcXWN6Ru+CRERD6s6//VbSROSnpb01Xav+zyl62+r/iVVb/rOa33cM1eYTJOxt3eqOrX3K792\nLfVD7V73ecjY2/dJetz2i5IeVfWb+Zx/4HT0Ou5MXA0gnJD0qYj4XbfX02/ob/vQ2/bpld726hF3\nV9i+yfaA7bepujToFUl/6PKy+gb9bR962z692FuC+/99UNIRSf+U9BFV5/xe7u6S+gr9bR962z49\n11tOlQBAMhxxA0AyBDcAJNOuyclGzr+MjY3V1mzZsqW2ZtWqVUX7GxkZqa1ZuHBh0bYKnO/gQMfO\nba1YsaK2ZnJysmhb27Ztq61Zs2ZN0bYK9Hxv9+3bV1tT2o/h4Zkmucv3V2guAy+N9Hf79u21NVu3\nbq2tWbx4cW2NJB08WH9pe6dzgSNuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZHrl\n1mVvqGS45ujRo7U1zz//fNH+Fi1aVFuza9eu2pp169YV7a/XDQwM1Nbs37+/aFtNDpz0uvHx8dqa\nlStX1tYsWFB2n+mJiYmiugxKBmdKvgdHR0drazZtKvtnsUsGcG688caibTWFI24ASIbgBoBkCG4A\nSIbgBoBkCG4ASIbgBoBkCG4ASIbgBoBkujaAU3JRe8lwzeHDh2trlixZUrSmkjvllKw7wwBOyZBI\ng3dNKbpLS7948MEHa2uGhoZqa0oHku66666iugw2btxYW1MymLds2bLamtI74HR6uKYER9wAkAzB\nDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJdG0Ap+SuNEuXLq2tKR2uKVFy0X4GO3bsqK3Z\ntm1bbc3U1FQDq6msWLGisW31us2bN9fWDA4ONrIdSVq9enVRXQYl389HjhyprSkZ3isdrCnJqoUL\nFxZtqykccQNAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACTT0wM4JXekaVIvXmh/PkoG\nNzZs2FBb0+TXOjk52di2uqnk6ygZgCq5S06pnTt3NratDEqGdE6dOlVbUzqAU1K3d+/e2pomv584\n4gaAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZLo2OVkyRXTw4MFG9lUyESlJ\nBw4cqK1Zv379XJdzQRofH6+tGR4e7sBK5qbklm/33HNPI/t64IEHiuoGBgYa2V8/KcmXkmlHSdq0\naVNtzfbt22trRkZGivZXgiNuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZLo2gFNy\n+6GSgZixsbFGakpt2bKlsW0hn5Jbvu3bt6+25tChQ7U1a9euLViRtHr16tqaknWvWbOmaH/dtnXr\n1tqaktuNlQ7m7dmzp7am04N5HHEDQDIENwAkQ3ADQDIENwAkQ3ADQDIENwAkQ3ADQDIENwAk09MD\nOCV3lSgZiFm+fHnRmpq6404GJXdNKRns2L17d9H+SoZSSoZEuq3kLj0ld/spqSm5245U9v9gcHCw\ntibLAE7J3W02btzY2P5KhmtGR0cb218JjrgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmC\nGwCScUR0ew0AgFngiBsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZ\nghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsA\nkvkfiDN/okZBD1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f61ec1c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Select the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1500 images to be used for training/testing sets\n",
    "digits.images = digits.images[:1500]\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "n_samples = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: a PLA classifier\n",
    "perceptron = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a classifier: a logistic classifier\n",
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_size = int(n_samples * (2/3))\n",
    "\n",
    "X_train = data[:training_size]\n",
    "X_test = digits.target[:training_size]\n",
    "\n",
    "y_train = data[training_size:n_samples]\n",
    "y_test = digits.target[training_size:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.fit(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validate and evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_perceptron = y_test\n",
    "predicted_perceptron = perceptron.predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_logistic = y_test\n",
    "predicted_logistic = logistic.predict(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926\n"
     ]
    }
   ],
   "source": [
    "perceptron_accuracy = np.sum(predicted_perceptron==expected_perceptron)/len(expected_perceptron)\n",
    "print(perceptron_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  3  2  0  2  0  0  0  0  1]\n",
      " [ 0 42  0  1  0  0  0  2  2  0]\n",
      " [ 0  0 48  0  0  1  0  0  0  0]\n",
      " [ 0  0  0 46  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  0  0  0]\n",
      " [ 1  0  0  1  0 49  0  0  2  4]\n",
      " [ 0  1  0  0  0  1 50  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 48  0  0]\n",
      " [ 0  3  0  1  0  1  0  0 44  7]\n",
      " [ 0  0  0  0  1  0  0  0  0 38]]\n"
     ]
    }
   ],
   "source": [
    "perceptron_confusion_matrix = confusion_matrix(predicted_perceptron, expected_perceptron)\n",
    "print(perceptron_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = np.sum(predicted_logistic==expected_logistic)/len(expected_logistic)\n",
    "print(logistic_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  0  1  0  0  0  0  0  0  1]\n",
      " [ 0 43  0  0  0  0  0  0  3  0]\n",
      " [ 0  0 49  0  0  1  0  0  1  0]\n",
      " [ 0  0  0 46  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 48  0  0  0  0  0]\n",
      " [ 1  0  0  1  0 50  0  0  2  0]\n",
      " [ 0  0  0  0  1  1 50  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  0]\n",
      " [ 0  2  0  1  0  0  0  0 42  0]\n",
      " [ 0  4  0  1  1  0  0  0  0 49]]\n"
     ]
    }
   ],
   "source": [
    "logistic_confusion_matrix = confusion_matrix(predicted_logistic, expected_logistic)\n",
    "print(logistic_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
